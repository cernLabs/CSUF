"capital.gain",
"capital.loss",
"hours.per.week",
"native.country",
"high")
adult$high <- factor(ifelse(adult$high == " >50K", "yes", "no"))
any(sapply(adult, function(x) any(x == " ?")))
which(sapply(adult, function(x) any(x == " ?")))
adult <- adult[!adult$workclass == " ?",]
adult <- adult[!adult$occupation == " ?",]
adult <- adult[!adult$native.country== " ?",]
k = sample(1:30161, size = 9048, rep =F)
adult.train <- adult[-k,]
adult.test <- adult[k,]
sqrt(14)
# fit a random forest
fit.rf <- randomForest(high ~ ., data = adult.train, ntree = 100, mtry = 4, nodesize = 10)
# fit a random forest
library(randomForest)
# fit a random forest
library(randomForest)
fit.rf <- randomForest(high ~ ., data = adult.train, ntree = 100, mtry = 4, nodesize = 10)
View(fit.rf)
adult <- read.csv("adult.data")
# name the columns
names(adult) <- c("age",
"workclass",
"fnlwgt",
"education",
"education.num",
"marital.status",
"occupation",
"relationship",
"race",
"sex",
"capital.gain",
"capital.loss",
"hours.per.week",
"native.country",
"y")
# make change the high column to a boolean
adult$y <- factor(ifelse(adult$y == " >50K", "yes", "no"))
any(sapply(adult, function(x) any(x == " ?")))
which(sapply(adult, function(x) any(x == " ?")))
adult <- adult[!adult$workclass == " ?",]
adult <- adult[!adult$occupation == " ?",]
adult <- adult[!adult$native.country== " ?",]
k = sample(1:30161, size = 9048, rep =F)
adult.train <- adult[-k,]
adult.test <- adult[k,]
# fit a random forest
library(randomForest)
fit.rf <- randomForest(y ~ ., data = adult.train, ntree = 100, mtry = 4, nodesize = 10)
# confusionmatrix for the random forest
View(adult)
# confusionmatrix for the random forest
adult.test$rf0_yhat = predict(fit.rf, newdata = adult.test, type = "raw")
# confusionmatrix for the random forest
adult.test$rf0_yhat = predict(fit.rf, newdata = adult.test, type = "response")
View(adult.test)
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)
# confusionmatrix for the random forest
library(caret)
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
}
table1(cmat_0,"initial randForest")
View(cmat_0)
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)$table
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)
View(cmat_0)
table1(cmat_0$table,"initial randForest")
fit.rf$variable.importance
fit.rf$importance
hist(fit.rf$importance)
fit.rf$importance
plot(fit.rf$importance)
fit.rf$importance
fit.rf$importance[,1]
fit.rf$importance[,2]
rownames(fit.rf$importance) -> rn
cmat_0[["table"]]
rn
plot(rn, fit.rf$importance)
hist(rn, fit.rf$importance)
hist(rn, as.vector(fit.rf$importance))
fit.rf$importance
fit.rf$importanceSD
fit.rf$importance
install.packages("vip")
library(vip)
vi(fit.rf)
hist(vi(fit.rf))
?barplot
vi(fit.rf) -> X
View(X)
barplot(X$Importance,names.arg = X$Variable)
barplot(X$Importance,names.arg = X$Variable, horiz = T)
library(vip)
vi(fit.rf) -> X
barplot(X$Importance,names.arg = X$Variable, horiz = T,las = 2, cex.names = 0.8)
library(vip)
vi(fit.rf) -> X
barplot(X$Importance,names.arg = X$Variable, horiz = F,las = 2, cex.names = 0.8)
?tree
adult <- read.csv("adult.data")
# name the columns
names(adult) <- c("age",
"workclass",
"fnlwgt",
"education",
"education.num",
"marital.status",
"occupation",
"relationship",
"race",
"sex",
"capital.gain",
"capital.loss",
"hours.per.week",
"native.country",
"y")
# make change the high column to a boolean
adult$y <- factor(ifelse(adult$y== " >50K", "yes", "no"))
any(sapply(adult, function(x) any(x == " ?")))
which(sapply(adult, function(x) any(x == " ?")))
adult <- adult[!adult$workclass == " ?",]
adult <- adult[!adult$occupation == " ?",]
adult <- adult[!adult$native.country== " ?",]
k = sample(1:30161, size = 9048, rep =F)
adult.train <- adult[-k,]
adult.test <- adult[k,]
# fit a random forest
library(randomForest)
fit.rf <- randomForest(y ~ ., data = adult.train, ntree = 100, mtry = 4, nodesize = 10)
# confusionmatrix for the random forest
library(caret)
adult.test$rf0_yhat = predict(fit.rf, newdata = adult.test, type = "response")
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
}
table1(cmat_0$table,"initial randForest")
# variables importance test is here
library(vip)
vi(fit.rf) -> X
barplot(X$Importance,names.arg = X$Variable, horiz = F,las = 2, cex.names = 0.8)
# let's try different things
v.ns = c(5,10,20) # put into node size
v.nt = c(100,500,1000) # put into ntrees
v.mt = c(3,4,5) # put into mtry
# intialize the results
ROW <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), accuracy = numeric())
# run the long loop
for(i in v.ns){
for(j in v.nt){
for(k in v.mt){
# feed these into the forest
atm.rf <- randomForest(y ~ ., data = adult.train, ntree = j, mtry = k, nodesize = i)
oobERR = atm.rf$err.rate[ntree, "OOB"]
# Store results
ROW <- rbind(ROW, data.frame(ntree = j, mtry = k, nodesize = i, accuracy = 1 - oobERR))
}
}
}
# intialize the results
ROW <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), accuracy = numeric())
# run the long loop
for(i in v.ns){
for(j in v.nt){
for(k in v.mt){
# feed these into the forest
atm.rf <- randomForest(y ~ ., data = adult.train, ntree = j, mtry = k, nodesize = i)
oobERR = atm.rf$err.rate[j, "OOB"]
# Store results
ROW <- rbind(ROW, data.frame(ntree = j, mtry = k, nodesize = i, accuracy = 1 - oobERR))
}
}
}
table1(cmat_0$table,"initial randForest")->p
p$a
p
p
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
return(list("accuracy" = a, "precision" = p, "recall" = r))
}
table1(cmat_0$table,"initial randForest")
table1(cmat_0$table,"initial randForest")
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
return(list("model.name" = s,"accuracy" = a, "precision" = p, "recall" = r))
}
table1(cmat_0$table,"initial randForest")
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
return(list("model.name" = model_name,"accuracy" = a, "precision" = p, "recall" = r))
}
table1(cmat_0$table,"initial randForest")
# intialize the results
ROW <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), accuracy = numeric())
# run the long loop
for(i in v.ns){
for(j in v.nt){
for(k in v.mt){
# feed these into the forest
atm.rf <- randomForest(y ~ ., data = adult.train, ntree = j, mtry = k, nodesize = i)
yhat.atm = predict(atm.rf, newdata = adult.test, type = "response")
cmat.atm <- confusionMatrix(yhat.atm, adult.test$y)
table1(cmat.atm$table,"model at the moment")$accuracy -> acc
ROW <- rbind(ROW, data.frame(ntree = j, mtry = k, nodesize = i, accuracy = acc))
}
}
}
adult <- read.csv("adult.data")
# name the columns
names(adult) <- c("age",
"workclass",
"fnlwgt",
"education",
"education.num",
"marital.status",
"occupation",
"relationship",
"race",
"sex",
"capital.gain",
"capital.loss",
"hours.per.week",
"native.country",
"y")
# make change the high column to a boolean
adult$y <- factor(ifelse(adult$y== " >50K", "yes", "no"))
any(sapply(adult, function(x) any(x == " ?")))
which(sapply(adult, function(x) any(x == " ?")))
adult <- adult[!adult$workclass == " ?",]
adult <- adult[!adult$occupation == " ?",]
adult <- adult[!adult$native.country== " ?",]
set.seed(5333)
k = sample(1:30161, size = 9048, rep =F)
adult.train <- adult[-k,]
adult.test <- adult[k,]
# fit a random forest
library(randomForest)
fit.rf <- randomForest(y ~ ., data = adult.train, ntree = 100, mtry = 4, nodesize = 10)
# confusionmatrix for the random forest
library(caret)
adult.test$rf0_yhat = predict(fit.rf, newdata = adult.test, type = "response")
cmat_0 <- confusionMatrix(adult.test$rf0_yhat, adult.test$y)
# display for accuracy, precision, recall, f1score
table1 <- function(confusion_matrix,model_name){
confusion_matrix -> tab
tab[1,1] -> tn
tab[2,2] -> tp
tab[1,2] -> fp
tab[2,1] -> fn
a = (tp+tn)/(tp+tn+fp+fn)
p = tp/(tp+fp)
r = tp/(tp+fn)
sprintf("%s || Accuracy: %f | Precision: %f | Recall(TPR): %f",model_name,a,p,r)
return(list("model.name" = model_name,"accuracy" = a, "precision" = p, "recall" = r))
}
table1(cmat_0$table,"initial randForest")
# let's try different things
v.ns = c(5,10,20) # put into node size
v.nt = c(100,500,1000) # put into ntrees
v.mt = c(3,4,5) # put into mtry
set.seed(5333)
# intialize the results
ROW <- data.frame(ntree = numeric(), mtry = numeric(), nodesize = numeric(), accuracy = numeric())
# run the long loop
for(i in v.ns){
for(j in v.nt){
for(k in v.mt){
# feed these into the forest
atm.rf <- randomForest(y ~ ., data = adult.train, ntree = j, mtry = k, nodesize = i)
yhat.atm = predict(atm.rf, newdata = adult.test, type = "response")
cmat.atm <- confusionMatrix(yhat.atm, adult.test$y)
table1(cmat.atm$table,"model at the moment")$accuracy -> acc
ROW <- rbind(ROW, data.frame(ntree = j, mtry = k, nodesize = i, accuracy = acc))
}
}
}
# get the best model
opt <- ROW[which.max(ROW$accuracy), ]
print(opt)
View(opt)
opt[1]
# variables importance test is here
bestfit.rf <- randomForest(y ~ ., data = adult.train, ntree = opt[1], mtry = opt[2], nodesize = opt[3])
# variables importance test is here
opt = as.vector(opt)
bestfit.rf <- randomForest(y ~ ., data = adult.train, ntree = opt[1], mtry = opt[2], nodesize = opt[3])
opt
opt[1,1]
View(opt)
# get the best model
opt <- ROW[which.max(ROW$accuracy), ]
print(opt)
# variables importance test is here
bestfit.rf <- randomForest(y ~ ., data = adult.train, ntree = opt[1], mtry = opt[2], nodesize = opt[3])
library(vip)
vi(bestfit.rf) -> X
barplot(X$Importance,names.arg = X$Variable, horiz = F,las = 2, cex.names = 0.8)
# variables importance test is here
bestfit.rf <- randomForest(y ~ ., data = adult.train, ntree = 500, mtry = 3, nodesize = 10)
library(vip)
vi(bestfit.rf) -> X
barplot(X$Importance,names.arg = X$Variable, horiz = F,las = 2, cex.names = 0.8)
opt[1,1]
?tree
# tree training
library(tree)
?tree()
?rpart()
# tree training
library(rpart)
simple.tree <- rpart(y ~., data = adult.train, method = "class")
rpart.plot(simple.tree)
plot(simple.tree)
library(tree)
?dt()
?tree()
simple.tree <- tree(y ~., data=adult.train)
plot(simple.tree)
rpart.plot(simple.tree)
library(rpart.plot)
install.packages("rpart.plot")
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test, type ="response")
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test, type = "raw")
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test, type = "class")
# tree training
library(rpart)
library(rpart.plot)
simple.tree <- rpart(y ~., data = adult.train, method = "class")
rpart.plot(simple.tree)
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test, type = "class")
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test)
# tree training
library(rpart)
library(rpart.plot)
simple.tree <- rpart(y ~., data = adult.train, method = "class")
rpart.plot(simple.tree)
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test)
confusionMatrix(tree.yhat,adult.test$y) -> cmat.stree
# tree training
library(rpart)
library(rpart.plot)
simple.tree <- rpart(y ~., data = adult.train, method = "class")
rpart.plot(simple.tree)
# accuracy
tree.yhat <- predict(simple.tree, newdata = adult.test, type = "class")
confusionMatrix(tree.yhat,adult.test$y) -> cmat.stree
table1(cmat.stree$table, "simple tree")
library(kable)
library(kableExtra)
library(kableExtra)
kable(ROW)
?sort()
?sort_by()
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy))
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),main = "comparison of decision tree perfomance")
?kable()
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),label = "comparison of decision tree perfomance")
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
par(mfrow = c(1,3))
plot(ROW$mtry,ROW$accuracy)
plot(ROW$ntree,ROW$accuracy)
plot(ROW$nodesize,ROW$accuracy)
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
par(mfrow = c(1,3))
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy")
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy")
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy")
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
cor(ROW$mtry,ROW$accuracy)
?plot()
# visualize
par(mfrow = c(1,3))
cor(ROW$mtry,ROW$accuracy)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = cor(ROW$mtry,ROW$accuracy))
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy")
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy")
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
cor(ROW$mtry,ROW$accuracy)
# visualize
par(mfrow = c(1,3))
COR = cor(ROW$mtry,ROW$accuracy)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = paste("cor :",COR))
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy")
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy")
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
cor(ROW$mtry,ROW$accuracy)
# visualize
par(mfrow = c(1,3))
COR = round(cor(ROW$mtry,ROW$accuracy),5)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = paste("cor :",COR))
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy")
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy")
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
cor(ROW$mtry,ROW$accuracy)
# visualize
par(mfrow = c(1,3))
COR = round(cor(ROW$mtry,ROW$accuracy),5)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = paste("cor :",COR))
COR = round(cor(ROW$ntree,ROW$accuracy),5)
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy",
sub = paste("cor :",COR))
COR = round(cor(ROW$nodesize,ROW$accuracy),5)
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy",
sub = paste("cor :",COR))
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
cor(ROW$mtry,ROW$accuracy)
# visualize
par(mfrow = c(1,3))
COR = round(cor(ROW$mtry,ROW$accuracy),5)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = paste("cor :",COR))
COR = round(cor(ROW$ntree,ROW$accuracy),5)
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy",
sub = paste("cor :",COR))
COR = round(cor(ROW$nodesize,ROW$accuracy),5)
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy",
sub = paste("cor :",COR))
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
# visualize
par(mfrow = c(1,3))
COR = round(cor(ROW$mtry,ROW$accuracy),5)
plot(ROW$mtry,ROW$accuracy, xlab = "mtry", ylab = "accuracy",
sub = paste("correlation :",COR))
COR = round(cor(ROW$ntree,ROW$accuracy),5)
plot(ROW$ntree,ROW$accuracy, xlab = "tree number", ylab = "accuracy",
sub = paste("correlation :",COR))
COR = round(cor(ROW$nodesize,ROW$accuracy),5)
plot(ROW$nodesize,ROW$accuracy, xlab = "node size", ylab = "accuracy",
sub = paste("correlation :",COR))
library(kableExtra)
kable(sort_by(ROW,ROW$accuracy),caption = "comparison of decision tree perfomance")
yhat.atm = predict(bestfit.rf, newdata = adult.test, type = "response")
cmat.atm <- confusionMatrix(yhat.atm, adult.test$y)
table1(cmat.atm$table,"model at the moment")
table1(cmat.atm$table,"model at the moment")
table1(cmat_0$table,"initial randForest")
table1(cmat.atm$table,"best fit random forest")
table1(cmat_0$table,"initial randForest")
