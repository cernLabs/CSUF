---
title: "Exam 3"
author: "Michael Pena"
date: "2024-06-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tseries)
library(forecast)
```

## Question 1

We found previously that
$$
\nabla_4X_t = 4\beta_1 + Z_t + Z_{t-4} 
$$
for the seasonal differencing, we find that 

$$
\nabla_4 \nabla X_t = -Z_{t-1} -Z_{t-4} + Z_{t-5}
$$
One has more parameters than the other. essentially in the end we want to go with the model that works with less parameters and does the same job in the end; less parameters means less work for the same result (we would pick the seasonal differenced pathway).

## Question 2

```{r}
# define the coeffs
phi = 0.6
the = 0.9
# save simulations into a matrix
SIM  <- matrix(0,100,3)
SIM[,1] <- arima.sim(n=100, list(ar = phi, ma = the))
SIM[,2] <- arima.sim(n=100, list(ar = phi))
SIM[,3] <- arima.sim(n=100, list(ma = the))
```

```{r}
# plot the timeseries
name = c("ARMA(1,1)","ARMA(1,0)","ARMA(0,1)")
for(i in 1:3){plot.ts(SIM[,i],main = name[i], ylab = "X_t")}
```

```{r}
# plot the ACFs
for(i in 1:3){acf(SIM[,i],main = name[i],ylab = "rho(h)")}
```

```{r}
# plot the PACFs
for(i in 1:3){pacf(SIM[,i],main = name[i],ylab = "alpha(h)")}
```

The models seem to match the table we went over in class; I do think that even though there seems to be a significant peak in the ARIMA(1,0) PACF, it seems not to peak over enough to claim to be an ARIMA(2,0) model.

## Question 3

```{r}
# get the data
library(astsa)
# make models
ar.ols(cmort,order= 2) -> cmort.ar2
arima(cmort, order = c(2,0,0)) -> cmort.arima200
cmort.ar2$x.intercept
summary(cmort.arima200)
```

```{r}
ts.plot(cmort, main = "fitting with ar.ols()", ylab = "Mortality")
lines(fitted(cmort.ar2),col = 'red')

```
```{r}
ts.plot(cmort, main = "fitting with arima()", ylab = "Mortality")
lines(fitted(cmort.arima200),col = 'skyblue')
```

## Question 4

### part (a)

```{r}
# getting data
demand <- as.vector(read.csv("Demand-2.txt", head = T)[,1])
series <- ts(demand, start =c(1992,1), frequency = 12)
series.train <- ts(demand[1:263], start =c(1992,1), frequency = 12)
series.val <- ts(demand[264:287], start =c(2014,1), frequency = 12)

par(mfrow=c(1,2))
plot.ts(series.train)
plot.ts(log(series.train))
acf(series.train)
acf(log(series.train))
boxplot(series.train)
boxplot(log(series.train))
```

Going to try more transforms

```{r}
plot.ts(sqrt(series.train))
plot.ts((series.train)^(1/3))
```


```{r}
# fit linear model :|
t = time(series.train)
fit0 <- lm(series.train ~ t)
fit1 <- lm(series.train ~ t + t^2)
fit2 <- lm(series.train ~ t + t^2 + t^3)
fit3 <- lm(series.train ~ t + t^2 + t^3 + t^4)
fit4 <- lm(sqrt(series.train) ~ t)
fit5 <- lm((series.train)^(1/3) ~ t)

par(mfrow = c(2,2))
plot(fit0)
plot(fit1)
plot(fit2)
plot(fit3)
plot(fit4)
plot(fit5)
```

the scale-location line doesn't seem to straighten out for any linear fit we do. I am going to difference.

```{r}
#difference once 

series.trainD <- diff(series.train,diff = 1)
# run kpss test
series.trainD_decomp <- decompose(series.trainD,type = c("additive"))
series.trainD_decomp <- na.omit(series.trainD_decomp)
kpss.test(series.trainD_decomp$random)
```

The test concludes a failure to reject null, there is a chance that the system is stationary, so lets check variance again.

```{r}
par(mfrow=c(2,2))
plot(lm(series.trainD ~ time(series.trainD)))
```

Yay. It is stabalized now!

### part (b)

```{r}
# render graphs the single out random cycles of 12
par(mfrow=c(2,2))
plot.ts(series.trainD[25:36])
plot.ts(series.trainD[145:156])
plot.ts(series.trainD[217:228])
```
It seems in the later months, there are peaks at the 2nd, 6th, and 10th month while there are dips in the 4th, 7th, 9th and 12th month. This is not consistent in the earlier months.

```{r}
# decomposing the series.train (we have done this previously in (a))
plot(series.trainD_decomp) 
```

I feel it necessary to try a moving average smoother to find a trend less erratic.

```{r}
# trying kernal smoothing from the book pp.74
plot(series.trainD, main= "Kernal Smoother Overlay")
lines(ksmooth(time(series.trainD), series.trainD, "normal", bandwidth=1), lwd=2, col=4)
par(fig = c(.65, 1, .65, 1), new = TRUE) # the insert
gauss = function(x) { 1/sqrt(2*pi) * exp(-(x^2)/2) }
```
This looks close to what we got from the decomposed series before. Going to try a smoothing spline for this task.

```{r}
plot(series.trainD, main= "Kernal Smoothing Spline Overlay")
lines(smooth.spline(time(series.trainD), series.trainD, spar=.3), lwd=2, col=4)
```

Let's see how this compares to differencing a decomposing one more time.

```{r}
series.trainD2 <- diff(series.train,diff = 2)
series.trainD2_decomp <- decompose(series.trainD2,type = c("additive"))
series.trainD2_decomp <- na.omit(series.trainD2_decomp)
plot(series.trainD2_decomp) 
```
That made the general trend more spiked; let's stick with the MA kernal smoother.

```{r}
yspline.hat <- ts(smooth.spline(time(series.trainD), series.trainD, spar=.3)$y, start =c(1992,1), frequency = 12)
yspline.hat_decomp <- decompose(yspline.hat,type = c("additive"))
yspline.hat_decomp <- na.omit(yspline.hat_decomp)
plot(yspline.hat_decomp$random, main = "Random component")
plot(yspline.hat_decomp$seasonal, main = "Random component") 

```

```{r}
# testing both for stationarity
# residuals
yspline.hat_decompR <- na.omit(yspline.hat_decomp$random)
kpss.test(yspline.hat_decompR)
# seasonal
yspline.hat_decompS <- na.omit(yspline.hat_decomp$seasonal)
kpss.test(yspline.hat_decompS)
```

Both test statistics fall in the the "Fail To Reject" region; both systems are stationary.

### part (c)

```{r}
# let's deseason
series.trainD.Decomp <- stl(series.trainD, s.window	= "periodic")
plot(series.trainD.Decomp)
```


```{r}
par(mfrow = c(1,2))
acf(series.train)
pacf(series.train)
acf(yspline.hat, main = "deseasoned \n differenced once")
pacf(yspline.hat, main = "deseasoned \n differenced once")
acf(series.trainD, main = "differenced once")
pacf(series.trainD, main = "differenced once")
```

I believe it fair to suggest that 1 $\leq$ p $\leq$ 3 and q = 0 from the deseasoned graphs. Looking at the seasoned graphs, PACF seems to suggest that q could be 1.

We saw previously, after differencing once, seasonality every 12 months (s = 12); let's make d = 1.

We notice a spike in both graphs at every whole number (note the view of the graph cuts of after 2.0). This can imply P $\geq$ 2 and Q $\geq$ 2. I did not conduct seasonal differencing thus D = 0. 

### part (d)

The view of the ACF and PACF graphs cuts off after 2.0. There could be more spikes at later lags.

Let's use auto.arima() to comb through these parameters.

 p $\in [1,3]$
 q = 1
 d = 1
 P = $\in [2,4]$ 
 Q = $\in [2,4]$
 D = 0
 
Note P,Q will only go up to four because I want to save RAM.

```{r}
# running auto.arima
auto.arima(
  series.train,
  d = 1,
  D = 0,
  max.p = 3,
  max.q = 1,
  max.P = 4,
  max.Q = 4,
  max.d = 1,
  max.D = 0,
  start.p = 1,
  start.q = 1,
  start.P = 2,
  start.Q = 2,
  stepwise = T)
```

We have an AIC of 1182.91
auto.arima is telling us we should look into (1,1,0)(3,0,1)[12].

It is strange that this auto.arima() function is suggesting that q = 0 and Q = 1 but those parameters are not within the ranges I input. 

```{r}
# residual diagnostics
sys.auto <- arima(series.train,order = c(1,1,0),seasonal = list(order = c(3,0,1),period = 12))
sarima(series.train, p = 1, q = 0, d =1, P = 3, D = 0, Q = 1, S = 12)
Box.test(residuals(sys.auto), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys.auto$aic)
```
Auto.arima() suggested a model that does not do well according to the Box-Ljung test.

Using intuition, make q = 1 and Q = 2 and test that.

\newpage

```{r}
sys0 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(3,0,2),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 3, D = 0, Q = 2, S = 12)
Box.test(residuals(sys0), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys0$aic)
```
This is a better AIC and Ljung-Box test gives a much more hopeful conclusion.

I am going to try different values for P and Q and see if I can get better results
\newpage

```{r}
sys1 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(2,0,2),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 2, D = 0, Q = 2, S = 12)
Box.test(residuals(sys1), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys1$aic)
```

\newpage

```{r}
sys2 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(3,0,3),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 3, D = 0, Q = 3, S = 12)
Box.test(residuals(sys2), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys2$aic)
```

\newpage

```{r}
sys3 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(4,0,4),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 4, D = 0, Q = 4, S = 12)
Box.test(residuals(sys3), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys3$aic)
```

\newpage

sys2 had the lowest AIC and so I will try a seasonal diferenced fit with those parameters

```{r}
sys4 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(3,1,3),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 3, D = 1, Q = 3, S = 12)
Box.test(residuals(sys4), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys4$aic)
```

The AIC greatly improved and the Ljung-Box p values have more values above the dotted line. When I try another seasonal differencing I get an error. Let's try changing P & Q to 2

\newpage

```{r}
sys5 <- arima(series.train,order = c(1,1,1),seasonal = list(order = c(2,1,2),period = 12))
sarima(series.train, p = 1, q = 1, d =1, P = 2, D = 1, Q = 2, S = 12)
Box.test(residuals(sys5), lag = 20, type="Ljung-Box")
sprintf("this gives and AIC of %f", sys5$aic)
```

AIC is not as good as the last one but is definitely still low. Also the Ljung-Box P values chart has greatly improved. I am going to move forward with the following parameters

(1,1,1)(3,0,3)[12]
(1,1,1)(3,1,3)[12]
(1,1,1)(2,1,2)[12]

### part (e)

```{r}
# getting graphics
plot(forecast(sys2, h = 24, level = 0.95))
points(series.val,col='red',type="l")
plot(forecast(sys4, h = 24, level = 0.95))
points(series.val,col='red',type="l")
plot(forecast(sys5, h = 24, level = 0.95))
points(series.val,col='red',type="l")
```




The prediction interval is much smaller for (1,1,1)(3,0,3)[12]. The distance red and blue trends seems much tighter than the others. Let's see if SSE scores confirm this.

```{r}
forecast(sys2, h = 24, level = 0.95) -> fore1
forecast(sys4, h = 24, level = 0.95) -> fore2
forecast(sys5, h = 24, level = 0.95) -> fore3

sum((fore1$mean - series.val)^2) 
sum((fore2$mean - series.val)^2) 
sum((fore3$mean - series.val)^2) 
```
This confirms my intuition. ARIMA(1,1,1)(3,0,3)[12] performs the best out of all three models. I believe it is in the companies best interest to use this model for future analysis because of how much better it preforms compared to all the other models test.
