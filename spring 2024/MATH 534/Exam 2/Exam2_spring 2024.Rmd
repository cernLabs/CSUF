---
title: "Exam 2"
author: "Mori Jamshidian"
date: "Spring 2024"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
---
\newcommand{\code}[1]{\textcolor{blue}{\texttt #1}}
\newcommand{\file}[1]{\textcolor{violet}{\texttt #1}}
\newcommand{\solution}[1]{\textcolor{orange}{#1}}
\newcommand{\pts}[1]{\textcolor{brown}{[#1 Points] }}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/githubbahubba/CSUF/spring 2024/MATH 534/Exam 2")
```
\newcommand{\bx}{\large\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bbeta}{\boldsymbol{\beta}}

\newpage

# Exam Rules and Instructions

(1)	You must work on this exam individually. Any communication with others about this exam in any form is considered cheating. Should you have any questions, please send an email to mori@fullerton.edu.

(2)	 Copying solutions from an Internet source or any other source would be considered plagiarism and will be dealt with according to university policy. 

(3)	You are not allowed to distribute the questions on this exam in any form or share the questions with anyone during the exam or anytime after the due-date.

(4)	 Your solutions must be typewritten. You must submit a single pdf file that would include your solutions, R codes, and R outputs. Additionally submit your Rmarkdown file.

(5)	Your solutions must appear in the order of the problem numbers. If you donâ€™t know the answer to a problem, write the problem number, and leave a blank space.


(8)	I reserve the right to interview you about the exam after I grade your exam.

(9) Submit your solution to Canvas. 

(10) A total of 55 points is possible.

\newpage

# Problem 1

We wanted to investigate marijuana use among college students. We surveyed 2000 randomly selected college students and asked them the following question: "In your best estimation, how many marijuana joints, if any, have you smoked the past thirty days?" We obtained 2000 values ranging from 0 to 27. A barplot of the data is given below.

```{r, Result = TRUE, echo = FALSE}
a <- read.csv(file = "Problem1_Data.csv", header = TRUE)
barplot(table(a$x))
```

Let $x_i$ denote the number of joints smoked by the $i$-th individual surveyed. As shown in the barplot, many students said that they have not smoked at all $(x_i=0)$, and because of this large number of zeros and the fact that the proportions do not monotonically decrease, a Poisson model would not be appropriate. To model the data, we assumed there are three groups: a proportion $\alpha$ of students (group 1) who, for whatever reason, report that they have not smoked marijuana even if this is not true (note that some might not be comfortable revealing that they smoke marijuana). A proportion $\beta$ of students (group 2) who smoke marijuana occasionally and respond truthfully. For group 2, we assume the number of joints that they smoke follows a Poisson distribution with mean $\mu$. Finally, a proportion $1-\alpha-\beta$ of students (group 3) who smoke marijuana more often and respond truthfully. For group 3, we assume the number of joints that they smoke follows a Poisson distribution with mean $\lambda$. Thus, we assume that each observation $x_i$ comes from the following mixture distribution:
\[
f(x_i) = \alpha \; 1_{\{x_i=0\}} + \beta\; \frac{e^{-\mu}\mu^{x_i}}{x_i!} +(1-\alpha-\beta)\; \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}
\]

where $1_{\{x_i=0\}} = 1$ if $x_i=0$, and it is zero otherwise. 


Your job in this problem is to use the EM algorithm to estimate the parameters $\theta = (\alpha, \beta, \mu, \lambda)$ using the data provided in the dataset `Problem3_Data.csv`. 

## **(a)** [3 Points] 

Write the (observed data) log-likelihood function.

$$\ell(\theta)=
n\Big(
log(\beta(1 - \alpha - \beta))-\mu -\lambda 
\Big) + \sum^{n}_{i=1} 
\Big(
x_i log\big[\frac{\mu\lambda}{(x_i!)^2}
\big]
\Big)$$

## **(b)** [3 Points] 

Describe the complete data, and derive the the complete data log-likelihood.

$$
\ell_c(\theta)=
\sum^{n}_{i=1} \Bigl[
z_{i1}log\alpha  + z_{i2}[log\beta - \mu +x_ilog\mu - log|x_i!|] + z_{i3}[log(1 - \alpha - \beta) - \lambda +x_ilog(\lambda) - log|x_i!|]
\Bigl]
$$

## **(c)** [3 points]

Obtain the $Q(\theta',\theta)$ function, including the formulas for the required expectations.

$$
Q(\theta'|\theta) = \sum^{N}_{i=1}\sum^{G}_{j=1}
E[Z_{ij}] \Big[
log[f(x_i|\theta')] + log\pi_j
\Big] \\
= \sum^{N}_{i=1}\Bigl[
E[z_{i1}]log\alpha  + E[z_{i2}][log\beta - \mu +x_ilog\mu - log|x_i!|] + E[z_{i3}][log(1 - \alpha - \beta) - \lambda +x_ilog(\lambda) - log|x_i!|]
$$

where 

$$
E[z_{i1}] = \frac{\alpha \; 1_{\{x_i=0\}}}{\alpha \; 1_{\{x_i=0\}} + \beta\; \frac{e^{-\mu}\mu^{x_i}}{x_i!} +(1-\alpha-\beta)\; \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}}\\
E[z_{i2}] = \frac{\beta \frac{e^{-\mu}\mu^{x_i}}{x_i!}}{\alpha \; 1_{\{x_i=0\}} + \beta\; \frac{e^{-\mu}\mu^{x_i}}{x_i!} +(1-\alpha-\beta)\; \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}}\\
E[z_{i3}] = \frac{(1-\beta-\alpha) \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}}{\alpha \; 1_{\{x_i=0\}} + \beta\; \frac{e^{-\mu}\mu^{x_i}}{x_i!} +(1-\alpha-\beta)\; \frac{e^{-\lambda}\lambda^{x_i}}{x_i!}}
$$



## **(d)** [4 points] 

Write formulas that maximize $Q(\theta',\theta)$ with respect to $\theta'$. That is, write the update formulas for $\alpha$, $\beta$, $\mu$, and $\lambda.$

$$
\alpha^* = \frac{(1-\beta)\sum^{N}_{i=1}E[z_{i1}]}{\sum^{N}_{i=1}E[z_{i1}] + E[z_{i3}]}
\\ \beta^* = \frac{(1-\alpha)\sum^{N}_{i=1}E[z_{i2}]}{\sum^{N}_{i=1}E[z_{i2}] + E[z_{i3}]}
\\ \mu^* = \frac{\sum^{N}_{i=1}E[z_{i2}]x_i}{\sum^{N}_{i=1}E[z_{i2}]}
\\ \lambda^* = \frac{\sum^{N}_{i=1}E[z_{i3}]x_i}{\sum^{N}_{i=1}E[z_{i3}]}
$$

## **(e)** [4 points] 

Give the formulas for the elements of the gradient of the log-likelihood function.

$$
\frac{\partial\ell}{\partial\alpha} =
\frac{n}{\alpha + \beta -1} \\
\frac{\partial\ell}{\partial\beta} =
\frac{n(1-\alpha-2\beta)}{\beta(1 -\alpha - \beta)}\\
\frac{\partial\ell}{\partial\mu} =
-n + \frac{1}{\mu} \sum^{n}_{i=1}x_i\\
\frac{\partial\ell}{\partial\lambda} =
-n + \frac{1}{\lambda} \sum^{n}_{i=1}x_i
$$


## **(f)** [9 points] 

Write an R function to implement the EM algorithm, and a function to compute the gradient of the log-likelihood. Your EM function should input $\alpha$, $\beta$, $\mu$, $\lambda$, the data `x`, and a parameter `maxiter` for the maximum number of iteration. To get full credit, you must use the following instructions:

- Write a functions to compute the gradient of the log-likelihood.

- Write a function to compute the required expectations. 

- Write a function that implements the EM algorithm. This function should call the gradient and the expectation functions. At each iteration print the iteration number, $\alpha$, $\beta$, $1-\alpha-\beta$, $\mu$, $\lambda$, and the norm of the gradient, in that order; use `norm(name_of_gradient, "2)`.

- Show all the functions that you write.

- Use the following parameter values to run your EM function: $\alpha = 1/3$, $\beta = 1/3$, $\mu = 1$, $\lambda = 30$, and `maxiter = 30`.

- Print all iterations.

```{r}
# making gradient of the llh function
LLgrad <- function(theta,X){
 # take elements
 n = length(X)
 a = theta[1]
 b = theta[2]
 mu = theta[3]
 lam = theta[4]
 # input the calculations
 dda = n/(a+b-1)
 ddb = n*(1-a-2*b)/(b*(1-a-b))
 ddmu = -n + (1/mu)*sum(X)
 ddlam = -n + (1/lam)*sum(X)
 # output
 return(c(dda,ddb,ddmu,ddlam))
}

# expectation calculations
expec <- function(F1,F2,F3,P1,P2,P3){
 nu1 = F1 * P1
 nu2 = F2 * P2
 nu3 = F3 * P3
 D = nu1 + nu2 + nu3
 E1 = nu1/D
 E2 = nu2/D
 E3 = nu3/D
 EZ = as.matrix(cbind(E1,E2,E3))
 return(EZ)
}

#  EM algorithm
EM_alg <- function(alpha,beta,mu,lam,X,maxit){
 # define N
 N <- length(X)
 # make prints
 header = paste0("iteration ","alpha     ","beta      ","1-beta-alpha","mu       ","lambda    ","gradnorm")
 
 # loop part
 for(q in 1:maxit){
   PI = c(alpha,beta,1-alpha-beta)
   # get f1
   f1 = rep(0,N)
   for(i in 1:N){
    if(X[i]==0){f1[i]=1}
   }
   # get f2 and f3
   f2 = dpois(X,lambda = PI[2])
   f3 = dpois(X,lambda = PI[3])
   
   # run expectation update
   expec(f1,f2,f3,PI[1],PI[2],PI[3]) -> EZ
   
   #updates
   alpha1 <- (1-beta)*sum(EZ[1])/sum(EZ[1]+EZ[3])
   beta1 <- (1-alpha)*sum(EZ[2])/sum(EZ[2]+EZ[3])
   mu1 <- sum(EZ[2]*X)/sum(EZ[2])
   lam1 <- sum(EZ[3]*X)/sum(EZ[3])
   theta1 <- c(alpha1,beta1,mu1,lam1)
   gradnorm <- norm(LLgrad(theta1,X),"2")
   
   # print
   print(sprintf("%i    ","%8.8f      ","%8.8f      ","%8.8f      ","%8.8f      ","%8.8f      ","%8.8f      ",
                q,
                alpha1,
                beta1,
                1-alpha1-beta1,
                mu1,
                lam1,
                gradnorm))
   # resets
   alpha1 -> alpha
   beta1 -> beta
   mu1 -> mu
   lam1 -> lam
 }
 print(sprintf("The MLE's are alpha = %f, beta = %f, 1 - beta - alphha = %f, mu = %f, lambda = %f",
                alpha,
                beta,
                1-beta-alpha,
                mu,
                lambda))
}
```

```{r}
#run problem 
data <- read.csv("Problem1_Data.csv", head =T)

```


## **(g)** [3 Points]

Using your parameter estimates, explain your findings. Your explanation should involve interpretation of all of the parameters in the context of the problem.

## **(h)** [2 points]

We met a student who said that she smoked 9 joints in the past 30 days. What is the probability that this student belons to each of the three groups, 1, 2, or 3? Which group would you classify this student to?  Heuristic explanations don't get any points!

## **(i)** [5 points] 

Write an R function to numerically approximate the observed information matrix, and use it to obtain the standard errors of the parameter estimates. 


# Problem 2

Consider the function
\[g(x)=30x^2 (1-x)^2, \quad 0<x<1.\]

## **(a)** [4 points] 

Write an R function that uses the basic Monte Carlo method to compute the integral

\[
\theta = \int_a^b g(x)dx.
\]

for arbitrary values a and b that range in the interval [0,1], and provides a $100(1-\alpha)\%$ confidence interval for $\theta$. Specifically,

- the input to your program must be $a$, $b$, number of simulated values, a seed for the random number generation, and a confidence level $CL$ with default value of 0.95. Your program must check that the input variables $0\leq a < b\leq 1$, and the confidence level $CL$ is between 0 and 1. If not, the program must stop and print an error message.

- your program must generate values from uniform(a,b) for the Monte Carlo estimation.

- your program must output and print the Monte Carlo estimate of $\theta$, its estimate of standard error, and a $100(1-\alpha)\%$ confidence interval for $\theta$.

- After writing the program, use it to obtain the value of the integral for $a = 0.2$ and $b=0.6$. Use 10,000 simulated values and seed 338. Your output should include the Monte Carlo estimate of $\theta$, its estimate of standard error, and a 95% confidence interval for $\theta$.

```{r}
MC <- function(a,b,N,see.d,CL=.95){
  set.seed(see.d)
  # case one
    if( 0 <= a && a < b && b <= 1 && CL >= 0 && CL <= 1){
      #generate from unif
      u <- runif(N,a,b)
      #take monte carlo
      g.u = 30*u^2 * (1-u)^2
      theta.bar = mean(g.u)
      theta = (b-a)*theta.bar
      theta.se = (b-a)*sd(g.u)/sqrt(N)
      #conf interval
      zSE = qnorm(CL)*theta.se
      CI.vals = c(theta - zSE, theta + zSE)
      CI = c(min(CI.vals),max(CI.vals))
      #outputs
      return(list(theta = theta, "Stand Err" = theta.se, "Conf Interval" = CI))
    }
  # case two: invalid parameters
    else{
      print("Error!: Invalid parameters")
    }
}

MC(.2,.6,10000,338)
```


## **(b)** [3 points] 

Repeat part (a), but instead of generating values from uniform(a,b), suppose that you generate values from the Beta distribution with parameters $\alpha = 2$ and $\beta = 2$. Explain how you can use the beta distribution to estimate the integral. In your explanation specify what expectation you will be estimating and how you will estimate it. No R code is needed here.

for a Beta Distribution where $X \thicksim Beta(3,3)$ the pdf will match the match the curve $g(x) = 30x^2(1-x)^2$. Thus we really just need to find $P_{Beta}[0.2 \leq X \leq 0.6]$. Let's say I have generated 10000 values from a Beta distribution; I want the expectation of amount of the numbers between $a$ and $b$. This is simply a matter of generating an N-length random sample from a beta distribution and and counting the values between $a$ and $b$. We can take this expected value and then divide it by N to get the estimated integral value.

##  **(c)** [2 points] 

Write a formula for the variance of the estimate of $\theta$  in part (b), as a function of $Y\sim Beta(\alpha = 2, \beta=2)$ and explain how you would estimate this variance in you R program. Do not write R code here. Only give an explanation of what R function you would use and how.

$$
Var(\hat\theta) = \frac{1}{N}\sum^{N}_{i=1}I_{\{a<y_i<b\}} - \Biggl[\frac{1}{N}\sum^{N}_{i=1}I_{\{a<y_i<b\}}\Biggl]^2
$$

I would count the numbers in our samples that sampled from the Beta(3,3) distribution that are between 0.2 and 0.6 and divide that count by the N number of samples; this would be my $\theta$. I would then take this value and subtract it from $\theta^2$ to get my variance.

## **(d)** [4 points]

Write an R code to implement the methods that you described in parts (b) and (c). Your program should be written for general $a$, $b$, and $CL$ values again, and output and print the Monte Carlo estimate of $\theta$, its estimate of standard error, and a 95% confidence interval for $\theta$. Run your program using the same values for $a=0.2$, $b=0.6$, 10,000 simulated values, seed 338, and confidence level 95%. you must use the `rbeta` function to generate values from the beta distribution. 


```{r}
Y <- rbeta(10000,2,2)
fY <- Y*1.25
mean(fY)
```


# Problem 3

Consider the function
\[
h(x) = \frac{x^3}{1+x^2}.
\]
Let $X$ be a random variable with density function
\[
f(x) = \frac{e^{-x}}{1-e^{-1}} \quad 0\leq x \leq 1.
\]
We want to estimate $E(h(X)$, the expected value of $h(X)$.

## **(a)** [3 points] 

Write an R function that uses the basic Monte Carlo method to approximate the required integral. Specifically, generate 100,000 values from the random variable $X$, and use these values to estimate $E(h(X))$. Your function should output the Monte Carlo estimate of $E(h(X))$ and its estimate of standard error. Use seed 666.

```{r}
# setting seed
set.seed(666)
#generate random values
n = 100000
u <- runif(n)
fu <- exp(-u)*u^3/((1 - exp(-1))*(1+u^2))
#expectation
E <- mean(fu)
# standard error
SE <- sd(fu)/sqrt(100000)
E
SE
```


## **(b)**  [3 points]

Here you repeat part (a), but use the method of Antithetic Sampling to estimate $E(h(X)] and its standard error. Write a step by step algorithm (pseudo code) for solving this problem. No R code here.
[Hint: you need to generate 50,000 samples from Uniform(0,1).] 

 + save 50000 samples from a uniform distribution (0,1) in a vector u

 + render the first part of the function were ```fu1 = exp(-u)*u^3/((1 - exp(-1))*(1+u^2))```

 + render second part by making v = 1 - u and then set ```fu2 = exp(-v)*v^3/((1 - exp(-1))*(1+v^2))```

 + theta will be the mean of the sum of vectors fu1 and fu2

 + StandErr will be the ```sqrt((1/(2*n)))*(sd(fu1+fu2))```

## **(c)** [4 points] 

Write an R function to implement the algorithm. Your function should output the estimate of $E(h(X))$ and its estimate of standard error. Use seed 666.

```{r}
# set seed
set.seed(666)
# render samples
u <- runif(n/2)
v = 1 - u
# render discrete functions
fu1 = exp(-u)*u^3/((1 - exp(-1))*(1+u^2)) 
fu2 = exp(-v)*v^3/((1 - exp(-1))*(1+v^2))
# get theta and SE
thetaAnti = (1/n)*sum(fu1 + fu2)
thetaAntiSE = sqrt((1/(2*n)))*(sd(fu1+fu2))
# print
thetaAnti;thetaAntiSE
```


## **(d)** [3 points] 

Explain the relationship between the standard error of the estimate of $E(h(X))$ obtained using the method of Antithetic Sampling as compared to the standard error of the estimate of $E(h(X))$ obtained using the basic Monte Carlo method. Show this relationship by computing relevant quantities using your R code.
  
```{r}
real = 0.113762652609
abs(real-0.1141116)
abs(real-0.1137378)
```

